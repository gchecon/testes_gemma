# Cosmopedia Dataset

O **Cosmopedia Dataset** é uma coleção extensa e diversificada de fontes textuais sintéticas, gerada pelo modelo Mixtral-8x7B-Instruct-v0.1. Este dataset é notável por sua grandeza, contendo mais de 30 milhões de arquivos e aproximadamente 25 bilhões de tokens, o que o torna o maior dataset sintético aberto disponível atualmente.

## Características Principais

- **Diversidade de Conteúdo:** Inclui uma ampla variedade de fontes textuais, como livros didáticos, postagens de blogs, narrativas, entradas de mídia social e artigos do WikiHow.
- **Volume:** Mais de 30 milhões de arquivos individuais e cerca de 25 bilhões de tokens.
- **Acesso Aberto:** Disponível publicamente para pesquisadores e desenvolvedores, promovendo avanços em processamento de linguagem natural (PLN) e geração de linguagem.

## Subconjuntos do Cosmopedia

O dataset é composto por 8 subconjuntos distintos, cada um abrangendo uma área específica de conhecimento ou tipo de texto:

1. **auto_math_text:** 1.95M linhas
2. **khanacademy:** 24.1k linhas
3. **Openstax:** 126k linhas
4. **Stanford:** 1.02M linhas
5. **Stories:** 4M linhas
6. **web_samples_v1:** 12.4M linhas
7. **web_samples_v2:** 10.3M linhas
8. **wikiHow:** 179k linhas

## Aplicação no Processamento de Linguagem Natural

A utilização do subset 'Stanford' para construir uma aplicação RAG ilustra como o Cosmopedia pode ser empregado para enriquecer a pesquisa em PLN. Ele oferece uma base de dados rica para treinamento de modelos de IA, melhorando a capacidade dos sistemas de entender e gerar linguagem de maneira mais eficaz.

Para mais informações sobre o Cosmopedia Dataset, visite [este link](https://github.com/huggingface/cosmopedia).

